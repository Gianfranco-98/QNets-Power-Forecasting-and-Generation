# Generic
from tqdm import tqdm
from typing import List

# Learning
import torch
import torch.nn as nn
import torch.nn.functional as F

# Metrics
from torchmetrics import MeanAbsolutePercentageError, PearsonCorrCoef

# Local files
from config import settings


class EnergyMetricsComputer(nn.Module):
    """ Energy-related Metrics Computer class """

    # Static variables with metric names
    energy_metrics = {
        "error metrics": {"mae", "mape", "rmse", "mbe"},
        "statistical metrics": {"pcorr", "cosi", "crps"},
        "extra metrics": {"es", "qs"}
    }

    def __init__(self, metrics: List[str]=["all"],
                 device: torch.device=settings["def_device"]):
        """ Energy Metrics Computer initialization

        Parameters
        ----------
        - `metrics`: list with names of the metrics to compute
        - `device`: computation device (e.g. 'cuda:0')
        """
        # Basic initialization
        super(EnergyMetricsComputer, self).__init__()
        self.metrics = metrics
        self.tgt_device = device

        # Metrics functions initialization
        self.mape_fun = MeanAbsolutePercentageError()
        self.pcorr_fun = PearsonCorrCoef()
        self.cosi_fun = nn.CosineSimilarity(dim=0)

    def error_metrics(self,
                      gen_scenarios: torch.Tensor,
                      true_scenario: torch.Tensor) -> dict:
        """ Compute all the error metrics

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `alg_dict`: dict with the following fields:
            - mae: Maximum Absolute Error dict
            - mape: Maximum Absolute Percentage Error dict
            - rmse: Root Mean Squared Error dict
            - mbe: Mean Bias Error dict
        """
        alg_dict = {}
        alg_dict["mae"] = self.mae(gen_scenarios, true_scenario)
        alg_dict["mape"] = self.mape(gen_scenarios, true_scenario)
        alg_dict["rmse"] = self.rmse(gen_scenarios, true_scenario)
        alg_dict["mbe"] = self.mbe(gen_scenarios, true_scenario)
        return alg_dict

    def statistical_metrics(self,
                            gen_scenarios: torch.Tensor,
                            true_scenario: torch.Tensor) -> dict:
        """ Compute all the statistical metrics

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `stat_dict`: dict with the following fields:
            - pcorr: Pearson's Correlation Coefficient dict
            - cosi: Cosine Similarity dict
            - crps: Continuous Rank Probability Score dict
        """
        stat_dict = {}
        stat_dict["pcorr"] = self.pcorr(gen_scenarios, true_scenario)
        stat_dict["cosi"] = self.cosi(gen_scenarios, true_scenario)
        stat_dict["crps"] = self.crps(gen_scenarios, true_scenario)
        return stat_dict

    def extra_metrics(self,
                      gen_scenarios: torch.Tensor,
                      true_scenario: torch.Tensor) -> dict:
        """ Compute all the extra metrics

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `supp_dict`: dict with the following fields:
            - es: Energy Score dict
            - qs: Quantile Score (pinball loss) dict
        """
        supp_dict = {}
        supp_dict["es"] = self.es(gen_scenarios, true_scenario)
        supp_dict["qs"] = self.qs(gen_scenarios, true_scenario)
        return supp_dict

    def mae(self,
            gen_scenarios: torch.Tensor,
            true_scenario: torch.Tensor) -> dict:
        """ Mean Absolute Error metric 

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `mae_dict`: metric_dict with MAE info
        """
        mae = torch.tensor(
            [F.l1_loss(g_s, true_scenario) for g_s in gen_scenarios])
        mae_dict = EnergyMetricsComputer.metric_to_dict(mae, "lower")
        return mae_dict

    def mape(self,
             gen_scenarios: torch.Tensor,
             true_scenario: torch.Tensor) -> dict:
        """ Mean Absolute Percentage Error metric 

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `mape_dict`: metric_dict with MAPE info
        """
        mape = torch.tensor(
            [self.mape_fun(g_s, true_scenario) for g_s in gen_scenarios])
        mape_dict = EnergyMetricsComputer.metric_to_dict(mape, "lower")
        return mape_dict

    def rmse(self,
             gen_scenarios: torch.Tensor,
             true_scenario: torch.Tensor) -> dict:
        """ Root Mean Squared Error metric 

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `rmse_dict`: metric_dict with RMSE info
        """
        rmse = torch.tensor(
            [torch.sqrt(F.mse_loss(g_s, true_scenario)) for 
             g_s in gen_scenarios])
        rmse_dict = EnergyMetricsComputer.metric_to_dict(rmse, "lower")
        return rmse_dict

    def mbe(self,
            gen_scenarios: torch.Tensor,
            true_scenario: torch.Tensor) -> dict:
        """ Maximum Bias Error metric 

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `mbe_dict`: metric_dict with MBE info
        """
        mbe = torch.tensor(
            [torch.mean(g_s - true_scenario) for 
             g_s in gen_scenarios])
        mbe_dict = EnergyMetricsComputer.metric_to_dict(mbe, "lower")
        return mbe_dict

    def pcorr(self,
              gen_scenarios: torch.Tensor,
              true_scenario: torch.Tensor) -> dict:
        """ Pearson's Correlation Coefficient metric

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `pcorr_dict`: metric_dict with PCORR info
        """
        pcorr = torch.tensor(
            [self.pcorr_fun(g_s, true_scenario) for g_s in gen_scenarios])
        pcorr_dict = EnergyMetricsComputer.metric_to_dict(pcorr, "higher")
        return pcorr_dict

    def cosi(self,
             gen_scenarios: torch.Tensor,
             true_scenario: torch.Tensor) -> dict:
        """ Cosine Similarity metric

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `cosi_dict`: metric_dict with COSI info
        """
        cosi = torch.tensor(
            [self.cosi_fun(g_s, true_scenario) for g_s in gen_scenarios])
        cosi_dict = EnergyMetricsComputer.metric_to_dict(cosi, "higher")
        return cosi_dict

    def crps(self,
             gen_scenarios: torch.Tensor,
             true_scenario: torch.Tensor) -> dict:
        """ Continuous Rank Probability Score metric [eNRG estimate]

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `crps_dict`: metric_dict with CRPS info
        """
        crps = []
        M = gen_scenarios.shape[0]
        gen_scenarios = gen_scenarios.T
        for hour in tqdm(range(len(gen_scenarios))):
            mae1 = torch.abs(gen_scenarios[hour] - true_scenario[hour]).mean()
            mae2 = 0.
            for g_s in range(M):
                mae2 += torch.abs(torch.sub(
                    gen_scenarios[hour][g_s], gen_scenarios[hour])).sum()
            crps.append(mae1 - mae2 / (2 * M ** 2))
        crps = 100 * torch.tensor(crps).reshape(-1, 24).mean(axis=0)
        crps_dict = EnergyMetricsComputer.metric_to_dict(crps, "lower")
        return crps_dict

    def es(self,
           gen_scenarios: torch.Tensor,
           true_scenario: torch.Tensor) -> dict:
        """ Energy Score metric

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `es_dict`: metric_dict with ES info
        """
        es = []
        M = gen_scenarios.shape[0]
        true_scenario = true_scenario.view(-1, 24)
        gen_scenarios = gen_scenarios.T.view(-1, 24, M).permute(0, 2, 1)
        for day in tqdm(range(len(true_scenario))):
            mne1 = torch.norm(torch.sub(
                gen_scenarios[day], true_scenario[day]), dim=-1).mean()
            mne2 = 0.
            for g_s in range(M):
                mne2 += torch.norm(torch.sub(
                    gen_scenarios[day][g_s], 
                    gen_scenarios[day]), dim=-1).sum()
            es.append(mne1 - mne2 / (2 * M ** 2))
        es = 100 * torch.tensor(es)
        es_dict = EnergyMetricsComputer.metric_to_dict(es, "lower")
        return es_dict

    def qs(self,
           gen_scenarios: torch.Tensor,
           true_scenario: torch.Tensor) -> dict:
        """ Quantile Score (Pinball Loss Function) metric

        Parameters
        ----------
        - `gen_scenarios`: power scenarios generated by the model
        - `true_scenario`: real power scenarios obatined from data

        Return
        ------
        `qs_dict`: metric_dict with QS info
        """
        qs = []
        hours = gen_scenarios.shape[1]
        q_t = torch.arange(0.01, 1.00, 0.01).double()
        gen_quantiles = torch.quantile(gen_scenarios, q_t, dim=0).T
        for q in tqdm(range(gen_quantiles.shape[1])):
            diff_q = true_scenario - gen_quantiles[:, q]
            qs.append(
                (torch.sum(q_t[q] * diff_q[diff_q >= 0]) / hours
                 + torch.sum((1 - q_t[q]) * (-diff_q[diff_q < 0])) / hours))
        qs = 100 * torch.tensor(qs)
        qs_dict = EnergyMetricsComputer.metric_to_dict(qs, "lower")
        return qs_dict

    def forward(self,
                gen_scenarios: torch.Tensor,
                true_scenario: torch.Tensor) -> dict:
        """ Energy Metrics effective computation

        Input:
            - `gen_scenarios`: power scenarios generated by the model
            - `true_scenario`: real power scenarios obatined from data

        Output:
            `metrics`: dict with the following structure:
                - error metrics: {'am1': {...}, 'am2': {...}, ...}
                - statistical metrics: {'sm1': {...}, 'sm2': {...}, ..}
                - extra metrics: {'em1': {...}, 'em2': {...}, ...}
        """
        metrics = {
            "error metrics": {},
            "statistical metrics": {},
            "extra metrics": {}}
        if self.metrics == ["all"]:
            metrics["error metrics"] = \
                self.error_metrics(gen_scenarios, true_scenario)
            metrics["statistical metrics"] = \
                self.statistical_metrics(gen_scenarios, true_scenario)
            metrics["extra metrics"] = \
                self.extra_metrics(gen_scenarios, true_scenario)
        else:
            for m in self.metrics:
                if "error" in m:
                    metrics["error metrics"] = \
                        self.error_metrics(gen_scenarios, true_scenario)
                elif "statistical" in m:
                    metrics["statistical metrics"] = \
                        self.statistical_metrics(gen_scenarios, true_scenario)
                elif "extra" in m:
                    metrics["extra metrics"] = \
                        self.extra_metrics(gen_scenarios, true_scenario)
                elif m == "mae":
                    metrics["error metrics"]["mae"] = \
                        self.mae(gen_scenarios, true_scenario)
                elif m == "mape":
                    metrics["error metrics"]["mape"] = \
                        self.mape(gen_scenarios, true_scenario)
                elif m == "rmse":
                    metrics["error metrics"]["rmse"] = \
                        self.rmse(gen_scenarios, true_scenario)
                elif m == "mbe":
                    metrics["error metrics"]["mbe"] = \
                        self.mbe(gen_scenarios, true_scenario)
                elif m == "pcorr":
                    metrics["statistical metrics"]["pcorr"] = \
                        self.pcorr(gen_scenarios, true_scenario)
                elif m == "cosi":
                    metrics["statistical metrics"]["cosi"] = \
                        self.cosi(gen_scenarios, true_scenario)
                elif m == "crps":
                    metrics["statistical metrics"]["crps"] = \
                        self.crps(gen_scenarios, true_scenario)
                elif m == "es":
                    metrics["extra metrics"]["es"] = \
                        self.es(gen_scenarios, true_scenario)
                elif m == "qs":
                    metrics["extra metrics"]["qs"] = \
                        self.qs(gen_scenarios, true_scenario)
        return metrics

    @staticmethod
    def metric_to_dict(metric_tensor: torch.Tensor,
                       order: str="lower") -> dict:
        """ Convert a tensor with metric values to dict 
        
        Parameters
        ----------
        - `metric_tensor`: tensor with metric values (shape [n_vals,])
        - `order`: 'higher' or 'lower' for the metric best values

        Return
        `metric_dict`: dict with the following fields:
            - value: value of the computed metric
            - best: value of the best computed metric
            - best_idx: idx of the best metric computed before
        """
        if order == "higher":
            best_idx = torch.argmax(metric_tensor)
        elif order == "lower":
            best_idx = torch.argmin(metric_tensor)
        best = metric_tensor[best_idx]
        metric_dict = {
            "value": float("%.4f" % metric_tensor.mean().item()),
            "best": float("%.4f" % best.item()),
            "best_idx": best_idx.item()
        }
        return metric_dict